{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies \n",
    "import os\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import requests\n",
    "import pymongo\n",
    "from splinter import Browser\n",
    "import pandas as pd\n",
    "from flask import Flask, redirect, render_template, jsonify\n",
    "import time\n",
    "from selenium import webdriver\n",
    "import lxml\n",
    "import urllib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize PyMongo to work with MongoDBs\n",
    "conn = 'mongodb://localhost:27017'\n",
    "client = pymongo.MongoClient(conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = client.quotes\n",
    "collection = db.quotes\n",
    "\n",
    "#browser=Browser(\"chrome\", headless=False)\n",
    "\n",
    "total_quotes=[]\n",
    "author_list=[]\n",
    "__id = 0 #counter\n",
    "\n",
    "for r in range(1,11):\n",
    "    url=f'http://quotes.toscrape.com/page/{r}'\n",
    "    response=requests.get(url)\n",
    "    #browser.visit(url)\n",
    "    soup=bs(response.text, \"lxml\")\n",
    "\n",
    "    ascrape=soup.find_all('div',{'class':'quote'})\n",
    "    for a in ascrape:\n",
    "        __id += 1 \n",
    "        tags_list=[]\n",
    "        quote=a.find('span', class_='text').text\n",
    "        author_name=a.find('small', class_='author').text\n",
    "        tags=a.find('div', class_='tags').find_all('a')\n",
    "        for tag in tags:\n",
    "            tag_text=tag.text.strip()\n",
    "            tags_list.append(tag_text)\n",
    "        #one_quote=[text,author,tags_list]\n",
    "        #total_quotes.append(one_quote)\n",
    "        href = a.a[\"href\"]\n",
    "        author_url = f'http://quotes.toscrape.com{href}'\n",
    "        author_response = requests.get(author_url)\n",
    "        author_soup = bs(author_response.text, 'lxml')\n",
    "        author_born = author_soup.find('span', class_ = 'author-born-date').text\n",
    "        author_desrp = author_soup.find('div', class_ = 'author-description').text\n",
    "        author = {\n",
    "            \"name\": author_name,\n",
    "            \"birthdate\": author_born,\n",
    "            \"description\": author_desrp\n",
    "        }\n",
    "        data = {\n",
    "            '__id': __id,\n",
    "            'quote': quote,\n",
    "            'author': author,\n",
    "            'tags': tags_list,\n",
    "        }\n",
    "        total_quotes.append(data)\n",
    "        collection.insert_one(data)\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "#     about_links=browser.find_by_text(\"(about)\")\n",
    "#     href_list=[]\n",
    "#     for l in about_links:\n",
    "#         ref=l['href']\n",
    "#         href_list.append(ref)\n",
    "#     for h in href_list:\n",
    "#         print(h)\n",
    "#         #browser.visit(h)\n",
    "#         req=requests.get(h)\n",
    "#         soup=bs(req.text, \"lxml\")\n",
    "#         author_birth=soup.find('span', class_=\"author-born-date\").text\n",
    "#         author_desc=soup.find('div', class_=\"author-description\").text\n",
    "#         author_name=soup.find('h3', class_=\"author-title\").text\n",
    "#         author_dict={'Name':author_name.strip(), 'Birthdate': author_birth.strip(), 'Bio':author_desc.strip()}\n",
    "#         author_list.append(author_dict)\n",
    "        \n",
    "#     quote_info = {\n",
    "#         'quote_text': text,\n",
    "#         'author': author,\n",
    "#         'tags': tags_list, \n",
    "#         'author_birthdate': author_birth,\n",
    "#         'author_description': author_desc\n",
    "#     }\n",
    "#     print(quote_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize PyMongo to work with MongoDBs\n",
    "conn = 'mongodb://localhost:27017'\n",
    "client = pymongo.MongoClient(conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define database and collection \n",
    "db = client.quote_db\n",
    "collection = db.quotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL of page to be scraped \n",
    "url = 'http://quotes.toscrape.com'\n",
    "\n",
    "# Retrieve page with the requests module \n",
    "response = requests.get(url)\n",
    "\n",
    "# Create BeautifulSoup object parse with 'html.parser'\n",
    "soup = BeautifulSoup(response.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "'return' outside function (<ipython-input-31-281f80e9e2db>, line 27)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-31-281f80e9e2db>\"\u001b[0;36m, line \u001b[0;32m27\u001b[0m\n\u001b[0;31m    return result.get_text()\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m 'return' outside function\n"
     ]
    }
   ],
   "source": [
    "# pages = np.arange(1,10,1)\n",
    "# for page in pages:\n",
    "\n",
    "# Retrieve the parent divs for all quotes \n",
    "results = soup.find_all('div', class_ = 'quote')\n",
    "scrapped = []\n",
    "\n",
    "\n",
    "# Loop over results to get quote data \n",
    "for result in results: \n",
    "    # Scrape Quote Text \n",
    "    quote_text = result.find('span', class_ = 'text').text\n",
    "    \n",
    "    # Scrage Tags \n",
    "    tags = result.find('div', class_ = 'tags').text\n",
    "    \n",
    "    # Scrape Author Name \n",
    "    author_name = result.find('small', class_ = 'author').text\n",
    "    \n",
    "    # Scrape Author Details \n",
    "    about_url = result.find('a').attrs['href']\n",
    "    new_url = f\"{url}{about_url}\" \n",
    "    \n",
    "    # print quote data \n",
    "    print(quote_text)\n",
    "    print(tags)\n",
    "    print(author_name)\n",
    "    print(new_url)\n",
    "    \n",
    "    # Dictionary to be inserted into MongoDB\n",
    "    quote_info = {\n",
    "        'quote_text': quote_text,\n",
    "        'tags': tags, \n",
    "        'author_name': author_name,\n",
    "    }\n",
    "    \n",
    "    # Insert dictionary into MongoDB as a document \n",
    "    collection.insert_one(quote_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "for result in soup.find_all('div', class_ = 'author-description'):\n",
    "    print(result.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "for result in soup.find_all(\"span\", {\"class\": \"author-born-date\"}):\n",
    "    print(result.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quotes = db.quotes.find()\n",
    "\n",
    "for quote in quotes:\n",
    "    print(quote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
